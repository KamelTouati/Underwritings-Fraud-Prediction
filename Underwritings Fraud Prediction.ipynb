{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the JSON file containing underwriting reports\n",
    "with open('underwritings.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Convert JSON to DataFrame\n",
    "underwriting_df = pd.DataFrame(data)\n",
    "underwriting_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Exploratory Data Analysis\n",
    "# print(underwriting_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(underwriting_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(underwriting_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Columns in underwriting_df:\", underwriting_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underwriting_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(underwriting_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of non-missing values in each column\n",
    "column_non_missing_percentage = (underwriting_df.notnull().mean() * 100)\n",
    "\n",
    "# Drop columns with less than 70% non-missing values\n",
    "columns_to_drop = column_non_missing_percentage[column_non_missing_percentage < 60].index\n",
    "print(\"columns_to_drop\", columns_to_drop)\n",
    "underwriting_df = underwriting_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(underwriting_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underwriting_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric columns\n",
    "numeric_cols = underwriting_df.select_dtypes(include=['int', 'float']).columns\n",
    "\n",
    "# Fill missing values in object columns with 'unknown'\n",
    "object_columns = underwriting_df.select_dtypes(include='object').columns\n",
    "underwriting_df[object_columns] = underwriting_df[object_columns].fillna(\n",
    "    'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# underwriting_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# underwriting_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'target_feature' is the name of your target feature\n",
    "target_correlation = underwriting_df.corrwith(\n",
    "    underwriting_df['clearfraudscore']).abs()\n",
    "\n",
    "# Set the threshold for correlation with the target feature\n",
    "threshold = 0.1  # You can adjust this threshold as needed\n",
    "\n",
    "# Find columns with correlation below the threshold\n",
    "low_correlation_columns = target_correlation[target_correlation <\n",
    "                                             threshold].index\n",
    "print(\"low_correlation_columns\", low_correlation_columns)\n",
    "print(\"len(low_correlation_columns)\", len(low_correlation_columns))\n",
    "\n",
    "# Drop the low correlation columns\n",
    "underwriting_df = underwriting_df.drop(columns=low_correlation_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(underwriting_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(underwriting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "X = underwriting_df.drop(columns=['clearfraudscore'])\n",
    "y = underwriting_df['clearfraudscore']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "# Further split the training data into training and validation sets (75% train, 25% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in y_train\n",
    "missing_values_y = y_train.isnull().sum()\n",
    "\n",
    "if missing_values_y > 0:\n",
    "    # Get indices of rows with missing values in y_train\n",
    "    missing_indices = y_train[y_train.isnull()].index\n",
    "\n",
    "    # Drop corresponding rows from X_train and y_train\n",
    "    X_train = X_train.drop(index=missing_indices)\n",
    "    y_train = y_train.drop(index=missing_indices)\n",
    "\n",
    "    # Reset index after dropping rows\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_val.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_cols = underwriting_df.drop(columns=['clearfraudscore']).select_dtypes(\n",
    "    include=['int', 'float']).columns\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# print(\"underwriting_df[numeric_cols]:\", underwriting_df[numeric_cols])\n",
    "print(\"underwriting_df[numeric_cols].isna().sum():\",\n",
    "      underwriting_df[numeric_cols].isna().sum())\n",
    "underwriting_df[numeric_cols].isna().sum()\n",
    "\n",
    "imputer.fit(underwriting_df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(imputer.statistics_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[numeric_cols] = imputer.transform(X_train[numeric_cols])\n",
    "X_test[numeric_cols] = imputer.transform(X_test[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric columns\n",
    "numeric_cols = X_train.select_dtypes(include=['int', 'float']).columns\n",
    "X_train[numeric_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(underwriting_df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Minimum:')\n",
    "list(scaler.data_min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Maximum:')\n",
    "list(scaler.data_max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[numeric_cols] = scaler.transform(X_train[numeric_cols])\n",
    "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[numeric_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = [col for col in X_train.columns if col !=\n",
    "                    'underwritingid' and X_train[col].dtype == 'object']\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all values in categorical columns to strings\n",
    "underwriting_df[categorical_cols] = underwriting_df[categorical_cols].astype(\n",
    "    str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# # One-hot encode categorical columns\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "encoder.fit(X_train[categorical_cols])\n",
    "\n",
    "# # Get the feature names for the encoded columns\n",
    "encoded_cols = list(encoder.get_feature_names_out(\n",
    "    input_features=categorical_cols))\n",
    "\n",
    "# # Transform the training and test data\n",
    "X_train_encoded = encoder.transform(X_train[categorical_cols])\n",
    "X_test_encoded = encoder.transform(X_test[categorical_cols])\n",
    "\n",
    "# # Create DataFrames from the encoded data\n",
    "X_train_encoded_df = pd.DataFrame(\n",
    "    X_train_encoded, columns=encoded_cols, index=X_train.index)\n",
    "X_test_encoded_df = pd.DataFrame(\n",
    "    X_test_encoded, columns=encoded_cols, index=X_test.index)\n",
    "\n",
    "# # Drop the underwritingid column\n",
    "X_train = X_train.drop(columns=['underwritingid'])\n",
    "X_test = X_test.drop(columns=['underwritingid'])\n",
    "\n",
    "# # Concatenate the encoded features with the original data\n",
    "X_train = pd.concat(\n",
    "    [X_train.drop(columns=categorical_cols), X_train_encoded_df], axis=1)\n",
    "X_test = pd.concat(\n",
    "    [X_test.drop(columns=categorical_cols), X_test_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[numeric_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the indices of rows with missing values in y_test\n",
    "indices_to_remove = y_test.index[y_test.isna()]\n",
    "\n",
    "# Drop rows with missing values from both X_test and y_test\n",
    "X_test = X_test.drop(indices_to_remove)\n",
    "y_test = y_test.drop(indices_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(targets, predictions):\n",
    "    return np.sqrt(np.mean(np.square(targets - predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.linear_model import Lasso\n",
    "# from sklearn.linear_model import ElasticNet\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "import xgboost as xgb\n",
    "# import lightgbm as lgb\n",
    "# from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate models\n",
    "# linear_reg = LinearRegression()\n",
    "# decision_tree = DecisionTreeRegressor()\n",
    "# random_forest = RandomForestRegressor()\n",
    "# gradient_boosting = GradientBoostingRegressor()\n",
    "# svm = SVR()\n",
    "\n",
    "# ridge_reg = Ridge()\n",
    "# lasso_reg = Lasso()\n",
    "# elastic_net_reg = ElasticNet()\n",
    "# knn_reg = KNeighborsRegressor()\n",
    "xgb_reg = xgb.XGBRegressor()\n",
    "# lgb_reg = lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of models\n",
    "# models = [linear_reg, decision_tree, random_forest, gradient_boosting, svm, ridge_reg, lasso_reg, elastic_net_reg, knn_reg, lgb_reg]\n",
    "\n",
    "model = xgb_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Perform cross-validation on the training data\n",
    "# cv_scores_train = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "# rmse_scores_train = np.sqrt(-cv_scores_train)\n",
    "\n",
    "# Calculate RMSE on the training data\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, model.predict(X_train)))\n",
    "\n",
    "# Calculate RMSE on the test data\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, model.predict(X_test)))\n",
    "\n",
    "# print(\"Training RMSE Scores:\", rmse_scores_train)\n",
    "# print(\"Training Mean RMSE:\", np.mean(rmse_scores_train))\n",
    "print(\"Training RMSE:\", rmse_train)\n",
    "print(\"Test RMSE:\", rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Find columns to drop, excluding 'clearfraudscore'\n",
    "# to_drop_test = [column for column in high_correlation.columns if column != 'clearfraudscore' and any(high_correlation[column])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns\n",
    "# test_data = test_data.drop(columns=to_drop_test)\n",
    "\n",
    "test_data = test_data.drop(columns=low_correlation_columns)\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric columns\n",
    "numeric_cols = test_data.select_dtypes(include=['int', 'float']).columns\n",
    "# print(numeric_cols)\n",
    "\n",
    "# Preprocess the test data\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "test_data[numeric_cols].isna().sum()\n",
    "\n",
    "imputer.fit(test_data[numeric_cols])\n",
    "test_data[numeric_cols] = imputer.transform(test_data[numeric_cols])\n",
    "\n",
    "scaler.fit(test_data[numeric_cols])\n",
    "test_data[numeric_cols] = scaler.transform(test_data[numeric_cols])\n",
    "\n",
    "categorical_cols = [col for col in test_data.columns if col !=\n",
    "                    'underwritingid' and test_data[col].dtype == 'object']\n",
    "\n",
    "# Convert all values in categorical columns to strings\n",
    "test_data[categorical_cols] = test_data[categorical_cols].astype(str)\n",
    "\n",
    "# print(categorical_cols)\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "test_encoded = encoder.transform(test_data[categorical_cols])\n",
    "\n",
    "# Create DataFrame from the encoded data\n",
    "test_encoded_df = pd.DataFrame(\n",
    "    test_encoded, columns=encoded_cols, index=test_data.index)\n",
    "\n",
    "# Drop the 'underwritingid' column (if present)\n",
    "if 'underwritingid' in test_data.columns:\n",
    "    test_data = test_data.drop(columns=['underwritingid'])\n",
    "\n",
    "# Concatenate the encoded features with the original test data\n",
    "test_data = pd.concat(\n",
    "    [test_data.drop(columns=categorical_cols), test_encoded_df], axis=1)\n",
    "\n",
    "# test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using each trained model\n",
    "test_predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the submission CSV file into a DataFrame\n",
    "submission_df = pd.read_csv('submission.csv')\n",
    "\n",
    "print(len(test_data))\n",
    "print(len(submission_df))\n",
    "print(len(test_predictions))\n",
    "\n",
    "# Check if the length of test_predictions matches the number of rows in submission_df\n",
    "if len(test_predictions) == len(submission_df):\n",
    "    # Add test_predictions as a new column named 'expected'\n",
    "    submission_df['expected'] = test_predictions\n",
    "\n",
    "    # Write the updated DataFrame back to the CSV file\n",
    "    submission_df.to_csv('submission.csv', index=False)\n",
    "else:\n",
    "    print(\"Length of test_predictions doesn't match the number of rows in submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
